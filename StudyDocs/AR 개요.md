# AR 개요

실제 공간에 가상의 물체를 혼합해 렌더링 하는 기술.  
카메라 영상을 통해 공간에 존재하는 평면, 빛을 인식하거나 자이로 센서 등을 함께 사용해 카메라의 공간상의 위치를 파악해서 카메라 영상을 입체로 분석하는 기술이 기반이 되어있다. 이렇게 분석한 공간을 기준으로 가상의 물체의 위치를 정하고, 현실의 물체에 가려지거나 빛의 영향을 받게 하는 것으로 가상의 물체가 현실에 포함된 것 같은 인식을 준다.

## 프로젝트 설정

* 안드로이드 기준

영상 분석에는 일반적으로 OpenCV가 사용되는데, OpenCV는 Vulkan을 지원하지 않는다. 따라서 `Project Settings`-`Player`-`Other Settings` 에서 `Auto Graphics API`를 체크 해제 후 Vulkan을 제거해서 그래픽 API중 Vulkan을 사용하지 않도록 해줘야 한다.  
또한 안드로이드 API 자체에도 AR을 작동시키기 위한 기능이 포함되어 있어야 하므로 `Minimum API Level`을 `Android 7.0`으로 선택한다.

`Scripting Backend`: 중간 언어로 CIL을 사용할지 C++까지 사용할지를 결정한다. IL2CPP를 선택해서 특히 모바일 환경에서의 성능 향상을 기대할 수 있다. 하지만 빌드 시간이 더 길어지는 점에 유의하자.

## AR 사용시의 유니티 장면

AR에서는 플레이어가 있는 현실 공간 위에 게임을 포함시키게 된다. 따라서 개발자가 환경부터 구성하던 다른 게임의 경우와 달리 입력에 따라 플레이어가 움직이는 것이 아니라, 플레이어가 마음대로 움직이고 그 움직임을 읽어와야 한다.

### AR Session과 AR Session Origin

기기의 각종 데이터(카메라, 자이로 등)를 통해 현실의 환경을 가져온다.  
유니티 월드상에서 AR Session은 가져온 현실 상황, AR Session Origin은 그 Session상에서 기기(카메라)의 위치와 회전 정보를 의미한다.  
(ARFoundation 4.x까지는 AR Session Origin, ARFoundation 5.x에서는 XR Origin)

### AR 시스템(AR Core)이 인식한 현실을 게임에서 사용하기

AR Core는 기기의 입력장치들로부터 현실의 지점들과 평면들을 인식하고, 유니티에선 이 정보를 게임에 사용한다. AR Core가 방의 벽과 바닥을 인식하면, 게임에서 가상의 공을 던져서 그 벽에 충돌하도록 할 수 있는 것이다.

* AR Raycast: 인식한 평면이 인식된 영역의 연장선상까지 뻗어있는 것으로 가정하고 Raycast를 하는 방식으로 평면 인식의 한계를 커버한다.
